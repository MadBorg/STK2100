---
title: "Oblig 1"
output:
  html_notebook: default
  pdf_document: default
---

## Problem 1


```{r, echo = F}
# Getting data
res_bodyfat <- read.csv("res_bodyfat/res_bodyfat.csv")
attach(res_bodyfat)
```

Aim: Find how well bmi, easily computed as the ratio between weight and squared hight (so mesured in kg/m^2), can be used to predict pbfm, whose measurment involves instead a bioelectrical impedance analysis.

### a

Plotting __bnp__ against __pbfm__, and fitting a simple linear model with a summary.

```{r}
plot(bmi, pbfm)
fit.simpleLinear <- lm(pbfm ~ bmi)
print(summary(fit.simpleLinear))
x = (seq(min(bmi), max(bmi), length = 200))
beta = coef(fit.simpleLinear)
lines(x, beta[1] + beta[2]* x, col = 2, lty = 1, lwd = 2)
```
A linear model seems ok in the center of the bmi. But it is quite off in the lower 1/4 and in the upper 1/4.We can see that the intercept and bmi is strongly significant, indicating a strong correlation between bmi and pdfm. The R-squared is siginificant, but not super high, so the model can probably be improved. To see this clearly we plott indicitative plotts on the fitness.

```{r}
plot(fit.simpleLinear)

```

#### Residuals vs Fitted

Shows the Anscombe plot, wich would idealy present a eaven scattering with no patterns in the points. In the plott we see a clear pattern, and is indicating possiple violation of homoscedasicity. Meaning that \epsiplon must be independent of the index.

#### Normal Q-Q

This plot shows quantile-quantile plot. This plot shows the values of the resiuals in increasing order. To see if the residuals folows a normal distribution. For the assumption of normality to be valid we would expect the values to folow the line in the plot. In the plot a heavy tail and head can be observed. So the assumtion of normality is not strong.

#### Scale-Location

#### Residual vs Leverage

## b

We can see that we dont have any negative number, in such cases it is often benefital to use a logarithmic transformation.

```{r}

fit.log <- lm(pbfm ~ log(bmi))
print(summary(fit.log))
beta = coef(fit.log)

x = log(seq(min(bmi), max(bmi), length = 200))
plot(bmi, pbfm)

lines(exp(x),( beta[1] + beta[2]* x), col = 2) 

```

And to see how good the model is we plot some helping plots

```{r}
plot(fit.log)
```


It was also suggested to use a quadratic model.

```{r}
fit.quad<- lm(pbfm ~ bmi + I(bmi^2))
print(summary(fit.quad))
beta = coef(fit.quad)

x = (seq(min(bmi), max(bmi), length = 200))
plot(bmi, pbfm)
#points(bmi, pbfm)
lines(x, beta[1] + beta[2]*x + beta[3]*x^2, col=2)
```
And the acopening helping plots

```{r}
plot(fit.quad)
```

## C - Leave-p-out cross-validation (https://en.wikipedia.org/wiki/Cross-validation_(statistics))

```{r}
max.p = 10
n = 4 # n = len bmi
shuffled = sample(1:length(bmi))
subset.size = length(bmi) %/% n
indices<-matrix(list(), nrow=n, ncol=1)
# indices[[1,1]] = shuffled[1:subset.size]
# indices[[2,1]] = shuffled[subset.size +1:subset.size*2]
# indices[[3,1]] = shuffled[(subset.size*2 + 1):subset.size*3]
# indices[[4,1]] = shuffled[(subset.size*3 + 1):length(bmi)]

for(i in 0:n-1){
  a = (subset.size*i) + 1
  b =  subset.size*(i+1)
  print(c(a,b))
  indices[[i+1,1]] = shuffled[a : b]
}



for (i in 1:max.p){
  for(j in 0:n){
      x = bmi[c(indices[[j %% n]], indices[[(j+1) %% n]], indices[[(j+2) %% n]])]
      y = pbfm[c(indices[[j %% n]], indices[[(j+1) %% n]], indices[[(j+2) %% n]])]
      fit = lm(pbfm ~ poly(x, i), x = TRUE)
      x.test = bmi[]
  }
}
```

## Problem 2

```{r, echo = F}
oral_ca <- read.csv("oral_ca/oral_ca.csv")
attach(oral_ca)
print(summary(oral_ca))
```
Aim of the study was to evaluate the risk of Oral cancer based on the variables __drinks__ (number og 1oz ethanol-equivalent drinks consumed per week), __sex__, __age__ and __cigs__ (number of cigaretts smoked per day).

### We are firs interested in the effect of smoking alone

#### (a)

Q: Dichotomize the variable cigs in two categories, smokers and not smokers, and create a table with the observed frequencies for cases and controls. In addition, provide the estimated probabilities (including their standard errors) of experiencing an oral cancer (i.e., being a case) for the two sub-populations.

A:
```{r}
N = nrow(oral_ca)
smokers = subset( oral_ca, oral_ca$cigs > 0 )#smokers = oral_ca[ oral_ca$cigs > 0]
nonSmokers = subset(oral_ca, oral_ca$cigs == 0) #  nonSmokers = oral_ca[ oral_ca$cigs == 0 ]
number.of.cc = nrow( subset(oral_ca,oral_ca$ccstatus == 1) )
number.of.cc.smokers = nrow( subset(oral_ca, oral_ca$ccstatus == 1 & oral_ca$cigs > 0) )
number.of.cc.nonSmokers = nrow(subset(oral_ca, oral_ca$ccstatus == 1 & oral_ca$cigs == 0) )
number.of.somkers = nrow( subset( oral_ca, oral_ca$cigs > 0) )
number.of.nonSmokers = nrow( subset( oral_ca, oral_ca$cigs == 0 ))

# Binomial - Mean
estProb = number.of.cc / N # Number of ppl with cancer devided on ppl (people in the query )
estProbSmoker = number.of.cc.smoker / number.of.somkers # Number of ppl with cancer and smokes, devided on number of ppl who smokes.
estProbNonSmoker = number.of.cc.nonSmoker / number.of.nonSmokers# Number of ppl with cancer and does not smoke, devided on number of ppl who does not soke.

# Binomial Vairance - Var(X) = n*p*(1-p)
estVar = N * estProb * (1 - estProb)
estVarSmoker = number.of.somkers * estProbSmoker * (1 - estProbSmoker)
estVarNonSmoker = number.of.nonSmokers * estProbNonSmoker * (1 - estProbNonSmoker)

cc.smoke.df = data.frame( colnames = "General", "Smoker", "Non Smoker"),
)
```

'






