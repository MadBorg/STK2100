---
title: "STK2100 Week 2 - Tasks"
output: html_notebook
---

```{r echo=FALSE, results='hide'}
# Getting the data
auto <- read.table("http://azzalini.stat.unipd.it/Book-DM/auto.dat", header = TRUE)
summary(auto)
attach(auto)

# Variables setup 
# sample size
n <- nrow(auto)
# create a dummy variable for fuel: diesel = FALSE, gasoline = TRUE
d <- fuel == "gas"

plot.engine.size.highway.distance <- function(title){
  #setting up the plot
  plot(engine.size, highway.distance, type= "n", main = title, ylab = "Higway distance (km/L)", xlab = "Engine size (L)")
  #plotting gas points
  points(engine.size[d], highway.distance[d])
  #plotting diesel points
  points(engine.size[!d], highway.distance[!d])
  legend('topright', pch = c(1, 2), col = c(4, 2),
         legend = c("Gasoline  ","Diesel"))
}


```



## 2.7

### q:
Fit an appropriate linear model to predict _higway distance_ for car data, in two ways: (a) using the variables described in this chapter; (b) using any variables listed in Appendix B.2

### a (a):

Showing highway distance vs. engine size:

```{r}

plot.engine.size.highway.distance("No model")

```

__Comment:__
  
From the plot it seems to be coorlated in a polynomial, log or 1/y way. But since x > 0 does not make sense we can try the log scale.
  
__Simple log linear model:__


```{r, echo=F}
### Figure log model ###
title = "Log model"
plot.engine.size.highway.distance(title)
fit.log = lm(highway.distance ~ log(engine.size) + fuel)
print(summary(fit.log))
x = seq(min(engine.size), max(engine.size), length = 200)
beta = coef(fit.log)
lines(x, beta[1] + beta[2]*log(x), col = 4, lty = 2)
lines(x,  beta[1] + beta[2]*log(x) + beta[3], col = 2, lty = 2)
legend('topright', pch = c(1, 2), col = c(4, 2), legend = c("Gasoline", "Diesel"))
```
__2nd Poly linear model:__
```{r, echo = F}
title = "2nd Poly linear model"
plot.engine.size.highway.distance(title)
fit.poly = lm(highway.distance ~ engine.size + I(engine.size^2) + fuel)
print(summary(fit.poly))
x = seq(min(engine.size), max(engine.size), length = 200)
beta = coef(fit.poly)
lines(x, beta[1] + beta[2]*x + beta[3]*x^2, col = 4, lty = 2)
lines(x, beta[1] + beta[2]*x + beta[3]*x^2 + beta[4], col = 2, lty = 2)
legend('topright', pch = c(1, 2), col = c(4, 2), legend = c("Gasoline", "Diesel"))
```


__Log and 1st poly linear model:__

```{r, echo=F}
title = "Log.1stPoly.model"
plot.engine.size.highway.distance(title)
fit.poly.log = lm(highway.distance ~ engine.size + log(engine.size) + fuel)
print(summary(fit.poly.log))
x = seq(min(engine.size), max(engine.size), length = 200)
beta = coef(fit.poly.log)
lines(x, beta[1] + beta[2]*x + beta[3]*log(x), col = 4, lty = 2)
lines(x, beta[1] + beta[2]*x + beta[3]*log(x) + beta[4], col = 2, lty = 2)
legend('topright', pch = c(1, 2), col = c(4, 2), legend = c("Gasoline", "Diesel"))
```

__LogLog linear model:__
```{r, echo=F}
title = "LogLog.model"
plot.engine.size.highway.distance(title)
fit.log.log = lm(log(highway.distance) ~ log(engine.size) + fuel)
print(summary(fit.log.log))
x = log(seq(min(engine.size), max(engine.size), length = 200))
beta = coef(fit.log.log)
lines(exp(x), exp(beta[1] + beta[2]*x), col = 4, lty = 2)
lines(exp(x), exp(beta[1] + beta[2]*x + beta[3]), col = 2, lty = 2)
legend('topright', pch = c(1, 2), col = c(4, 2), legend = c("Gasoline", "Diesel"))
```

### Comment:

It looks like the LogLog model is the best fitting one, from visual inspection and lokking at the adjusted R-squared. Therefor i chose to look further into this model.

```{r}
par(mfrow=c(1,2))
plot(engine.size, resid(fit.log.log), ylab = "residuals", xlab = "enginesize")
abline(0,0)
qqnorm(resid(fit.log.log))
qqline(resid(fit.log.log))

```

Residualplottet er ikke gjenvt fordelt og normalplottet har tung hale, og ikke helt rett senter. Så modellen ser ikke så bra ut.

### a (b):

```{r, echo=F}
plot.higway.distance.curb.weight <- function(title) {
  #setting up the plot
  plot(curb.weight, highway.distance, type= "n", main = title, ylab = "Higway distance (km/L)", xlab = "curb.weight (kg)")
  #plotting gas points
  points(curb.weight[d], highway.distance[d], col = 4, pch = 1)
  #plotting diesel points
  points(curb.weight[!d], highway.distance[!d], col = 2, pch = 2)
  legend('topright', pch = c(1, 2), col = c(4, 2),
         legend = c("Gasoline  ","Diesel"))
}

```

__Trying curb.weight to explain higway.distance__

```{r}
#plot
title = "linear linear model"
#setting up the plot
plot(curb.weight, highway.distance, type= "n", main = title, ylab = "Higway distance (km/L)", xlab = "curb.weight (kg)")
#plotting gas points
points(curb.weight[d], highway.distance[d], col = 4, pch = 1)
#plotting diesel points
points(curb.weight[!d], highway.distance[!d], col = 2, pch = 2)
legend('topright', pch = c(1, 2), col = c(4, 2),
       legend = c("Gasoline  ","Diesel"))

# lm
fit.lin.lin = lm(highway.distance ~ curb.weight + fuel)
print(summary(fit.lin.lin))

#adding data to plot
x = seq(min(engine.size), max(engine.size), length = 200)
beta = coef(fit.lin.lin)
lines(x, beta[1] + beta[2]*x, col = 4, lty = 2)
lines(x, beta[1] + beta[2]*x + beta[3], col = 2, lty = 2)
legend('topright', pch = c(1, 2), col = c(4, 2), legend = c("Gasoline", "Diesel"))

```



```{r, echo=F}
detach(auto)
```


# From ISLR

```{r, echo = F}
library(ISLR)
attach(Auto)
```


## 3.9 

This question involves the use of multiple linear regression on the
Auto data set.

### (a) Produce a scatterplot matrix which includes all of the variables in the data set.

```{r}
plot(Auto)

```

### (b) Compute the matrix of correlations between the variables using the function cor(). You will need to exclude the name variable, which is qualitative



```{r}
exclude = names(Auto) %in% c("name")
cor(Auto[!exclude])

```

### (c) Use the lm() function to perform a multiple linear regression with mpg as the response and all other variables except name as the predictors. Use the summary() function to print the results. Comment on the output. For instance:

```{r}
fit = lm(mpg ~ ., data=Auto[!exclude])
fit.sum = summary(fit)
fit.sum

```

i. Is there a relationship between the predictors and the response?
    * There seems to be a good relationship between the predictors and responce, lokking at R-squared, and a p-value wich is essentially zero
ii. Which predictors appear to have a statistically significant relationship to the response?
    * All the predictors with stars. 
iii. What does the coefficient for the year variable suggest?
    * ?
    
### (d) Use the plot() function to produce diagnostic plots of the linear regression fit. Comment on any problems you see with the fit. Do the residual plots suggest any unusually large outliers? Does the leverage plot identify any observations with unusually high leverage?

```{r}
plot(fit)
```

#### Residuals vs Fitted

(3.3.3.1): Non-linearity. Residual plot is used for identifying non-linearity. The red line is a smooth if to the residuals. A strong pattern in this plot will indicate non-linearity in the data, and opposite. where we can see a small pattern but not to strong. So we can say it's a pass.

#### Other comments
We do see some problem with the points 327, 394 in the leverage plot and 323, 327, and 326 in the residual plot. Thise points dont seem to be explained good by the model, wich probabli implies that we lack some relevant data, or that the model culd be improved.

###
