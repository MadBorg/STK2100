---
title: "oblig2"
author: "Sanders"
date: "4/7/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem 1.

### Reading dataset

```{r}
df <- read.csv("http://web.stanford.edu/~hastie/CASI_files/DATA/leukemia_big.csv",
               header = T,
               sep = ","
               )
N_gene_expressions = 7128
N_patiants = 72

ALL_patients = grepl("ALL", names(df))
AML_patients = grepl("AML", names(df))
```

###  a)

```{r}
library(pls)

PC_analysis = prcomp(t(df), center = T, scale = T, rank. = 2)
plot(
  PC_analysis$x, col=c("blue", "red"), main="lukemia", xlab="PC1", ylab = "PC2", pch=1
)
X = PC_analysis$x

points(X[ALL_patients,1], X[ALL_patients, 2], col = "4", pch = 19)
points(X[AML_patients,1], X[AML_patients, 2], col = "2", pch = 19)
legend("topleft", legend = c("ALL", "AML"), col = c(2, 4), pch = c(19, 19))

```

### b)

```{r}
library(glmnet)
target_df <- read.csv("https://www.uio.no/studier/emner/matnat/math/STK2100/v20/eksamen/response_train.csv",
               header = T,
               sep = ","
               )

# mod.Lasso.3 = glmnet(x = t(df), y = target_df[,2], alfa = 1, standardize = T, nfolds = 3)
lambda.l.a.3 = cv.glmnet(x =t(df), y = target_df[,2], alfa = 1, standardize = T, nfolds = 3)
lambda.l.a.3



# mod.Lasso.10 = glmnet(x = t(df), y = target_df[,2], alfa = 1, standardize = T, nfolds = 10)
lambda.l.a.10 = cv.glmnet(x =t(df), y = target_df[,2], alfa = 1, standardize = T, nfolds = 10)
lambda.l.a.10


# mod.Lasso.72 = glmnet(x = t(df), y = target_df[,2], alfa = 1, standardize = T, nfolds = 72)
lambda.l.a.72 = cv.glmnet(x =t(df), y = target_df[,2], alfa = 1, standardize = T, nfolds = 72)
lambda.l.a.72

```

The penalty method used in lasso might not just help with __parameter restriction__, but also might requier some coeffisients to be zero. Effectivly reducing the complexity of the model. This is using a absolute value constraint. Where lambda (s) is a shrinking parameter where the absolute sum of the betas shuld be smaller then lambda.

### c)


```{r}
mod.Lasso.3 = glmnet(x = t(df), y = target_df[,2], alfa = 1, standardize = T, nfolds = 3, lambda = lambda.l.a.3$lambda.min)
mod.Lasso.10 = glmnet(x = t(df), y = target_df[,2], alfa = 1, standardize = T, nfolds = 10, lambda = lambda.l.a.10$lambda.min)
mod.Lasso.72 = glmnet(x = t(df), y = target_df[,2], alfa = 1, standardize = T, nfolds = 72, lambda = lambda.l.a.72$lambda.min)

"Non zero indexes for Lasso 3"
which(mod.Lasso.3$beta != 0)
"Non zero indexes for Lasso 10"
which(mod.Lasso.10$beta != 0)
"Non zero indexes for Lasso 72"
which(mod.Lasso.72$beta != 0)

```

### d)

```{r}
N = 11

lambda.r = cv.glmnet(x = t(df), y = target_df[,2], alfa = 0)
best_lambda = lambda.r$lambda.min
mod.ridge = glmnet(x = t(df), y = target_df[,2], alfa = 0, lambda = best_lambda)
sort(mod.ridge$beta, decreasing = TRUE)[0:N-1] # ?


```

### e)


```{r}
# pcr.analysis = prcomp(t(df), center = T, scale = T, rank. = 2)
mod.pcr = pcr(target_df[,2]~., data = data.frame(t(df)), scale = T, validation = "CV")
validationplot(mod.pcr, val.type="MSEP" )
mod.pcr.small = pcr(target_df[,2]~t(df), scale = T, ncomp = 6)
#validationplot(mod.pcr.small, val.type="MSEP" )
mod.pcr.larger = pcr(target_df[,2]~t(df), scale = T, ncomp = 13)
#validationplot(mod.pcr.larger, val.type="MSEP" )
summary(mod.pcr)

```


